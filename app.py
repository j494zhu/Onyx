import os
import json
import requests
from groq import Groq

from flask import Flask, render_template, request, redirect, session, flash, jsonify
from flask_sqlalchemy import SQLAlchemy
from flask_login import UserMixin, LoginManager, login_user, logout_user, current_user, login_required
from werkzeug.security import generate_password_hash, check_password_hash
from datetime import datetime, timedelta, date
from itertools import groupby
from collections import OrderedDict
from sqlalchemy import and_, or_

from services.prompts import get_audit_prompt, get_weekly_audit_prompt
from services.stats import calculate_stats_from_logs, calculate_duration
from services.streak import update_user_streak
from services.history_helper import calculate_duration_minutes, build_day_stats

from dotenv import load_dotenv
load_dotenv()  # âœ… è‡ªåŠ¨è¯»å– .env æ–‡ä»¶ä¸­çš„å˜é‡

app = Flask(__name__)
app.secret_key = os.environ.get('SECRET_KEY')
XAI_API_KEY = os.environ.get('XAI_API_KEY')

database_url = os.environ.get('DATABASE_URL')
if database_url and database_url.startswith("postgres://"):
    database_url = database_url.replace("postgres://", "postgresql://", 1)
app.config['SQLALCHEMY_DATABASE_URI'] = database_url or 'sqlite:///site.db'


db = SQLAlchemy(app)

login_manager = LoginManager()
login_manager.init_app(app)
login_manager.login_view = 'login'

# --- è¾…åŠ©å‡½æ•°ï¼šè®¡ç®—â€œé€»è¾‘æ—¥æœŸâ€ ---
def get_logical_date(dt_obj):
    """
    å¦‚æœæ—¶é—´åœ¨ 00:00 åˆ° 06:00 ä¹‹é—´ï¼Œç®—ä½œå‰ä¸€å¤©ã€‚
    ä¾‹å¦‚: 1æœˆ30æ—¥ 03:00 -> é€»è¾‘ä¸Šæ˜¯ 1æœˆ29æ—¥
    """
    if dt_obj.hour < 6:
        return (dt_obj - timedelta(days=1)).date()
    return dt_obj.date()

# --- æ•°æ®åº“æ¨¡å‹ ---
class User(UserMixin, db.Model):
    id = db.Column(db.Integer, primary_key=True)
    username = db.Column(db.String(100), unique=True, nullable=False)
    password = db.Column(db.String(255), nullable=False)
    expenses = db.relationship('Expenses', backref='user', lazy=True)

    quick_note = db.Column(db.Text, default="")
    notebook = db.Column(db.Text, default="")

    streak = db.Column(db.Integer, default=0)
    last_check_in = db.Column(db.String(20), default=None)

class Expenses(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    desc = db.Column(db.String, nullable=False)
    start_time = db.Column(db.String, nullable=False)
    end_time = db.Column(db.String, nullable=False)
    timestamp = db.Column(db.DateTime, default=datetime.now)

    is_archived = db.Column(db.Boolean, default=False) 
    archive_date = db.Column(db.Date, nullable=True)   # è®°å½•è¿™æ¡æ•°æ®å±äºå“ªä¸€ä¸ª"é€»è¾‘æ—¥"
    user_id = db.Column(db.Integer, db.ForeignKey('user.id'), nullable=True)

    category = db.Column(db.String(50), default="Uncategorized")

class AlignmentSignal(db.Model):
    # è¿™æ˜¯ä½ çš„æ ¸å¿ƒèµ„äº§è¡¨ï¼šç”¨äºå­˜å‚¨ Human-in-the-Loop çš„è®­ç»ƒæ•°æ®
    id = db.Column(db.Integer, primary_key=True)
    
    # 1. å…³è”ç”¨æˆ· (è¿™å°±æ˜¯ä½ çš„ "Annotator")
    user_id = db.Column(db.Integer, db.ForeignKey('user.id'), nullable=False)
    
    # 2. Input (Context): å½“æ—¶å–‚ç»™ AI çš„æ•°æ®å¿«ç…§
    # è¿™é‡Œå­˜å‚¨ä½ å‘é€ç»™ DeepSeek/Gemini çš„ Prompt ä¸Šä¸‹æ–‡ï¼ˆæ¯”å¦‚å½“å¤©çš„ä»»åŠ¡åˆ—è¡¨ JSONï¼‰
    # ä»¥åè®­ç»ƒæ¨¡å‹æ—¶ï¼Œè¿™å°±æ˜¯ "User Prompt"
    input_context = db.Column(db.Text, nullable=False)
    
    # 3. Output (Prediction): AI ç»™å‡ºçš„å»ºè®®/æ€»ç»“
    # è¿™å°±æ˜¯ "Model Completion"
    ai_response = db.Column(db.Text, nullable=False)
    
    # 4. Reward Signal (Ground Truth): ä½ çš„åé¦ˆ
    # 1-5 åˆ†ï¼Œæˆ–è€… 0/1 (äºŒå…ƒåˆ†ç±»)ã€‚è¿™æ˜¯ RLHF ç®—æ³•æœ€éœ€è¦çš„ "Scalar Reward"
    reward_score = db.Column(db.Integer, nullable=False)
    
    # 5. Correction (Optional): å¦‚æœä½ è§‰å¾— AI è¯´å¾—ä¸å¯¹ï¼Œä½ å†™çš„ä¿®æ­£å»ºè®®
    # è¿™å±äº SFT (Supervised Fine-Tuning) æ•°æ®
    human_correction = db.Column(db.Text, nullable=True)
    
    # å…ƒæ•°æ®
    timestamp = db.Column(db.DateTime, default=datetime.now)

    # å»ºç«‹å…³ç³»ï¼Œæ–¹ä¾¿ä» User æŸ¥è¯¢
    user = db.relationship('User', backref=db.backref('alignment_signals', lazy=True))

@login_manager.user_loader
def load_user(user_id):
    return User.query.get(int(user_id))

# æ¯æ¬¡åº”ç”¨å¯åŠ¨è‡ªåŠ¨å»ºè¡¨ï¼ˆçœå»æ‰‹åŠ¨create_allï¼‰
with app.app_context():
    db.create_all()

# --- è·¯ç”±é€»è¾‘ ---

@app.route('/', methods=["POST", "GET"])
@login_required
def index(): # get user lgo entry; 
# it is one of the only three routings when the project was initially built :D
    # 1. POST: æ·»åŠ æ–°è®°å½•
    if request.method == 'POST':
        item_desc = request.form.get('desc')
        item_start = request.form.get('start_time')
        item_end = request.form.get('end_time')
        
        # æ–°å¢çš„è®°å½•ï¼Œé»˜è®¤å±äºå½“å‰çš„"é€»è¾‘æ—¥"
        logical_date = get_logical_date(datetime.now())
        
        try:
            item = Expenses(
                desc=item_desc, 
                start_time=item_start, 
                end_time=item_end, 
                user_id=current_user.id,
                is_archived=False,           # é»˜è®¤åœ¨é¦–é¡µæ˜¾ç¤º
                archive_date=logical_date    # æ ‡è®°å®ƒå±äºå“ªä¸€å¤©
            )
            db.session.add(item)
            update_user_streak(current_user, logical_date)
            db.session.commit()
            return redirect('/')
        except Exception as e:
            return f'Error: {str(e)}'

    # 2. GET: é¦–é¡µå±•ç¤º
    else:
        # [æ ¸å¿ƒé€»è¾‘] è‡ªåŠ¨æ£€æŸ¥ï¼šæ˜¯å¦å·²ç»æ˜¯"æ–°çš„ä¸€å¤©"äº†ï¼Ÿ
        # å¦‚æœç°åœ¨çš„é€»è¾‘æ—¥æœŸ > æŸäº›æœªå½’æ¡£è®°å½•çš„é€»è¾‘æ—¥æœŸï¼Œè¯´æ˜é‚£äº›è®°å½•è¯¥è¿‡æœŸäº†
        now = datetime.now()
        current_logical_date = get_logical_date(now)
        
        # æŸ¥å‡ºæ‰€æœ‰è¿˜åœç•™åœ¨é¦–é¡µ(is_archived=False)çš„è®°å½•
        active_items = Expenses.query.filter_by(user_id=current_user.id, is_archived=False).all()
        
        items_to_archive = False
        for item in active_items:
            # è®¡ç®—è¿™æ¡è®°å½•å±äºå“ªä¸€å¤©
            item_logical_date = get_logical_date(item.timestamp)
            
            # å¦‚æœè¿™æ¡è®°å½•å±äº"æ˜¨å¤©"æˆ–æ›´æ—©ï¼Œä¸”ç°åœ¨å·²ç»è¿‡äº†å‡Œæ™¨6ç‚¹(ä¹Ÿå°±æ˜¯è¿›å…¥äº†æ–°çš„é€»è¾‘æ—¥)
            if item_logical_date < current_logical_date:
                item.is_archived = True
                item.archive_date = item_logical_date # ç¡®ä¿å®ƒçš„å½’æ¡£æ—¥æœŸæ­£ç¡®
                items_to_archive = True
        
        if items_to_archive:
            db.session.commit()
        
        # é‡æ–°è·å–å‰©ä¸‹çš„ã€å±äºä»Šå¤©çš„è®°å½•
        expenses = Expenses.query.filter_by(user_id=current_user.id, is_archived=False).order_by(Expenses.timestamp.desc()).all()

        total_h, deep_h = calculate_stats_from_logs(expenses)

        # [NEW] è·å–å½“å‰ç”¨æˆ·çš„ RLHF æ ·æœ¬æ•°é‡
        rlhf_count = AlignmentSignal.query.filter_by(user_id=current_user.id).count()
        
        # [NEW] ç¨å¾®åŠ ç‚¹æˆï¼šè®¡ç®—ä¸€ä¸ªå‡çš„ "Model Confidence" (æ¨¡å‹ç½®ä¿¡åº¦)
        # é€»è¾‘ï¼šæ ·æœ¬è¶Šå¤šï¼Œç½®ä¿¡åº¦è¶Šé«˜ã€‚æ¯”å¦‚æ¯ 10 ä¸ªæ ·æœ¬æ¶¨ 1%ï¼Œèµ·æ­¥ 75%
        model_confidence = min(99, 75 + int(rlhf_count / 5))
            
        return render_template('index.html', expenses=expenses, total_hours=total_h, deep_hours=deep_h, rlhf_count=rlhf_count, model_confidence=model_confidence)

@app.route('/end_day', methods=['POST'])
@login_required
def end_day():
    """æ‰‹åŠ¨ç»“æŸä»Šå¤©ï¼šæŠŠé¦–é¡µæ‰€æœ‰å†…å®¹å¼ºåˆ¶å½’æ¡£"""
    active_items = Expenses.query.filter_by(user_id=current_user.id, is_archived=False).all()
    
    current_logical_date = get_logical_date(datetime.now())
    
    for item in active_items:
        item.is_archived = True
        # å¦‚æœæ˜¯æ‰‹åŠ¨ç»“æŸï¼Œå½’æ¡£æ—¥æœŸå°±æŒ‰å½“å‰çš„é€»è¾‘æ—¥æœŸç®—
        item.archive_date = current_logical_date

    # empty quick_note
    current_user.quick_note = ""
    # and do NOT change notebook
        
    db.session.commit()
    return redirect('/')


@app.route('/history')
@login_required
def history():
    """å†å²è®°å½•é¡µé¢ï¼šæŒ‰æ—¥/å‘¨åˆ†é¡µï¼Œæ—¶é—´è½´å¯¼èˆªï¼Œå¸¦æ¯æ—¥ç»Ÿè®¡"""

    # â”€â”€ 1. è§£æå‚æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    mode = request.args.get('mode', 'day')
    offset = request.args.get('offset', 0, type=int)

    today = date.today()

    if mode == 'week':
        current_monday = today - timedelta(days=today.weekday())
        start_date = current_monday + timedelta(weeks=offset)
        end_date = start_date + timedelta(days=6)
        label = f"{start_date.strftime('%Y-%m-%d')} â€” {end_date.strftime('%Y-%m-%d')}"
    else:
        start_date = today + timedelta(days=offset)
        end_date = start_date
        label = start_date.strftime('%Y-%m-%d (%A)')

    # â”€â”€ 2. æ•°æ®åº“æŸ¥è¯¢ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    items = Expenses.query.filter(
        Expenses.user_id == current_user.id,
        Expenses.is_archived == True,
        Expenses.archive_date.isnot(None),
        Expenses.archive_date >= start_date,
        Expenses.archive_date <= end_date,
    ).order_by(
        Expenses.archive_date.desc(),
        Expenses.timestamp.desc()
    ).all()

    # â”€â”€ 3. æŒ‰æ—¥æœŸåˆ†ç»„ + è®¡ç®—æ¯æ—¥ç»Ÿè®¡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    grouped_history = OrderedDict()  # { date: { 'items': [...], 'stats': {...} } }

    for archive_date, group in groupby(items, key=lambda x: x.archive_date):
        day_items = list(group)
        grouped_history[archive_date] = {
            'items': day_items,
            'stats': build_day_stats(day_items),
        }

    # â”€â”€ 4. èŒƒå›´çº§æ±‡æ€»ç»Ÿè®¡ï¼ˆé¡¶éƒ¨æ˜¾ç¤ºï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    total_entries = len(items)
    range_total_min = sum(d['stats']['total_minutes'] for d in grouped_history.values())
    range_total_hours = f"{range_total_min / 60:.1f}h"
    range_days = len(grouped_history)

    # â”€â”€ 5. å¯¼èˆªè¾¹ç•Œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if mode == 'week':
        next_disabled = (start_date + timedelta(weeks=1)) > today
    else:
        next_disabled = (start_date + timedelta(days=1)) > today

    prev_end = start_date - timedelta(days=1)
    has_older = Expenses.query.filter(
        Expenses.user_id == current_user.id,
        Expenses.is_archived == True,
        Expenses.archive_date.isnot(None),
        Expenses.archive_date <= prev_end,
    ).first() is not None

    return render_template(
        'history.html',
        grouped_history=grouped_history,
        mode=mode,
        offset=offset,
        label=label,
        total_entries=total_entries,
        range_total_hours=range_total_hours,
        range_days=range_days,
        start_date=start_date,
        end_date=end_date,
        next_disabled=next_disabled,
        has_older=has_older,
    )

# delete log
@app.route('/delete/<int:id>', methods=['POST'])
@login_required
def delete(id):
    del_item = Expenses.query.get_or_404(id)
    if (del_item.user_id != current_user.id):
        return "Unauthorized"
    try:
        db.session.delete(del_item)
        db.session.commit()
        return redirect('/')
    except Exception as e:
        return f"Error deleting item: {e}"

@app.route('/register', methods=['POST', 'GET'])
def register():
    # ... (ä¿æŒåŸæ¥çš„ä»£ç ) ...
    if request.method == 'POST':
        username = request.form.get('username')
        password = request.form.get('password')
        password_2 = request.form.get('password-confirm')
        user = User.query.filter_by(username=username).first()
        if user:
            return render_template('register.html', user_exists=True)
        if password != password_2:
            return render_template('register.html', password_mismatch=True)
        # Hash password
        new_user = User(username=username, password=generate_password_hash(password, method='pbkdf2:sha256'))
        db.session.add(new_user)
        db.session.commit()
        return redirect('/login')
    else:
        return render_template('register.html')

@app.route('/login', methods=['POST', 'GET'])
def login():
    # ... (ä¿æŒåŸæ¥çš„ä»£ç ) ...
    if request.method == 'POST':
        username = request.form.get('username')
        password = request.form.get('password')
        user = User.query.filter_by(username=username).first()

        # username exists and password matches:
        if user and check_password_hash(user.password, password):
            login_user(user)
            return redirect('/')

        # username exists but password is incorrect:
        if user:
            return render_template('login.html', wrong_password=True, user_dne=False)

        # username does not exist
        return render_template('login.html', user_dne=True, wrong_password=False)
    else:
        return render_template('login.html')

@app.route('/logout')
@login_required
def logout():
    logout_user()
    return redirect('/login')


# save notebook
@app.route('/save_notes', methods=['POST'])
@login_required
def save_notes():
    data = request.json
    note_type = data.get('type')
    content = data.get('content')

    if (note_type == 'quick_note'):
        current_user.quick_note = content
    else:
        current_user.notebook = content

    db.session.commit()
    return jsonify({"status": "success", "saved_at": datetime.now().strftime("%H:%M:%S")})


@app.route('/api/ai/audit', methods=['POST'])
@login_required
def ai_audit():
    # --- 1. é€Ÿç‡é™åˆ¶é€»è¾‘ (ä¿æŒä¸å˜) ---
    last_run = session.get('last_audit_time')
    now = datetime.now()
    
    if last_run:
        last_time = datetime.fromisoformat(last_run)
        if now - last_time < timedelta(seconds=10):
            return jsonify({
                "score": 0,
                "status": "red",
                "insight": "Cool down! System recharging.",
                "warning": "Rate limit exceeded. Wait 10s."
            }), 429

    session['last_audit_time'] = now.isoformat()

    # --- 2. æ”¶é›†æ•°æ® (ä¿æŒä¸å˜) ---
    data = request.get_json() or {} 
    user_tone = data.get('tone', 'strict')
    
    logical_date = get_logical_date(datetime.now())
    today_logs = Expenses.query.filter(
        Expenses.user_id == current_user.id,
        or_(
            Expenses.archive_date == logical_date,
            Expenses.is_archived == False
        )
    ).all()
    active_items = Expenses.query.filter_by(user_id=current_user.id, is_archived=False).all()
    
    logs_data = [f"{log.start_time}-{log.end_time}: {log.desc}" for log in today_logs]
    
    notebook = current_user.notebook
    quick_note = current_user.quick_note

    # è·å– Prompt æ–‡æœ¬
    prompt_text = get_audit_prompt(notebook, quick_note, logs_data, tone=user_tone)

    # --- 3. è°ƒç”¨ Grok API (æ ¸å¿ƒä¿®æ”¹ç‚¹) ---
    # è¿™é‡Œçš„ Key å»ºè®®ä¹‹åæ¢æˆç¯å¢ƒå˜é‡ï¼Œä»Šæ™šå…ˆè·‘é€š

    
    # æ„å»ºé€‚é… x.ai çš„ OpenAI å…¼å®¹æ ¼å¼è¯·æ±‚ä½“
    payload = {
        # ğŸ‘‘ å† å†›é€‰æ‹©ï¼šæ¯” Mini æ›´ä¾¿å®œï¼Œé€Ÿåº¦æå¿«
        "model": "grok-4-1-fast-non-reasoning", 
        
        "messages": [
            {
                "role": "system", 
                "content": "You are a concise log classifier. Always output valid JSON."
            },
            {
                "role": "user", 
                "content": prompt_text
            }
        ],
        "temperature": 0.1, # åˆ†ç±»ä»»åŠ¡ä¿æŒä½æ¸©ï¼Œç¡®ä¿ç¨³å®š
        "stream": False
    }

    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {XAI_API_KEY}"
    }

    try:
        # ä½¿ç”¨ requests å‘é€ POST è¯·æ±‚
        response = requests.post(
            "https://api.x.ai/v1/chat/completions", 
            headers=headers, 
            json=payload,
            timeout=30 # å¢åŠ è¶…æ—¶ä¿æŠ¤
        )
        response.raise_for_status() # å¦‚æœ 4xx æˆ– 5xx åˆ™æŠ›å‡ºå¼‚å¸¸
        
        full_res = response.json()
        raw_content = full_res['choices'][0]['message']['content']

        # æ¸…æ´—å¹¶è§£æ JSON
        clean_json = raw_content.replace("```json", "").replace("```", "").strip()
        return jsonify(json.loads(clean_json))

    except Exception as e:
        print(f"Grok Error: {str(e)}")
        return jsonify({
            "score": 0, 
            "status": "red", 
            "insight": "Grok Connection Failed", 
            "warning": f"Technical details: {str(e)}"
        })


@app.route('/api/visualize', methods=['POST'])
@login_required
def visualize_data():
    # A. è·å–ä»Šæ—¥æœ‰æ•ˆæ•°æ® (Raw Data)
    active_items = Expenses.query.filter_by(user_id=current_user.id, is_archived=False).all()
    
    if not active_items:
        return jsonify({"error": "No data to analyze"}), 400

    # B. [Context Retrieval] è·å–ç”¨æˆ·å†å²æ ‡ç­¾ (Memory)
    # è¿™æ˜¯ä¸ºäº†ä¿æŒåˆ†ç±»çš„ä¸€è‡´æ€§ (Consistency)
    existing_tags = []
    try:
        # æŸ¥è¯¢æœ€è¿‘ä½¿ç”¨çš„å‰ 20 ä¸ªä¸é‡å¤æ ‡ç­¾
        recent_tags_query = db.session.query(Expenses.category).filter(
            Expenses.user_id == current_user.id,
            Expenses.category != "Uncategorized",
            Expenses.category != None
        ).distinct().limit(20).all()
        existing_tags = [row[0] for row in recent_tags_query if row[0]]
    except Exception:
        pass # å¦‚æœæ•°æ®åº“åˆšé‡ç½®ï¼Œè¿™é‡Œå¯èƒ½ä¸ºç©ºï¼Œå¿½ç•¥é”™è¯¯

    tags_context = ", ".join(existing_tags) if existing_tags else "None yet"

    # C. æ„å»ºæ•°æ®åŒ…
    entries_text = "\n".join([f"ID_{item.id}: [{item.start_time}-{item.end_time}] {item.desc}" for item in active_items])

    # D. æ„å»º Prompt (High-Concept: Context-Aware Taxonomy)
    prompt = f"""
    You are a data taxonomy engine. Group the following logs into 3-6 high-level categories.
    
    [Context Memory]
    Existing Tags: {tags_context}
    (Prioritize using these tags if they fit. Create new ones only if necessary.)
    
    [Rules]
    1. Categories must be concise (1-2 words, e.g., "Coding", "Deep Work").
    2. Every entry must have exactly ONE category.
    3. Return ONLY valid JSON mapping Entry IDs to Categories.
    
    [Input Data]
    {entries_text}
    
    [Output Format]
    {{ "ID_1": "Coding", "ID_2": "Break" }}
    """

    # E. è°ƒç”¨ xAI (Grok)
    try:
        payload = {
            "model": "grok-4-1-fast-non-reasoning", # æˆ– gpt-4o-mini
            "messages": [
                {"role": "system", "content": "Output strictly JSON."},
                {"role": "user", "content": prompt}
            ],
            "temperature": 0.1, # ä½æ¸©ä»¥ä¿è¯ç¨³å®š
            "stream": False
        }
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {XAI_API_KEY}"
        }
        
        # å‘é€è¯·æ±‚
        response = requests.post("https://api.x.ai/v1/chat/completions", headers=headers, json=payload, timeout=30)
        response.raise_for_status()
        
        # è§£æç»“æœ
        ai_content = response.json()['choices'][0]['message']['content']
        clean_json = ai_content.replace("```json", "").replace("```", "").strip()
        mapping = json.loads(clean_json)

    except Exception as e:
        print(f"AI/Network Error: {e}")
        # å¦‚æœ AI æŒ‚äº†ï¼Œè¿”å›ä¸€ä¸ªç©ºçš„ç»“æ„ï¼Œé˜²æ­¢å‰ç«¯å´©æºƒ
        return jsonify({"error": "Taxonomy Engine Failed"}), 500

    # F. [Data Enrichment] æ›´æ–°æ•°æ®åº“ & è®¡ç®—ç»Ÿè®¡
    stats = {} 
    
    for item in active_items:
        key = f"ID_{item.id}"
        # è·å–åˆ†ç±» (å¦‚æœ AI æ¼äº†æŸä¸ªIDï¼Œå›é€€åˆ° 'Uncategorized')
        category = mapping.get(key, "Uncategorized")
        
        # å­˜å…¥æ•°æ®åº“ (æŒä¹…åŒ–æ ‡ç­¾)
        item.category = category
        
        # ç´¯åŠ æ—¶é—´
        duration = calculate_duration(item.start_time, item.end_time)
        stats[category] = stats.get(category, 0) + duration

    db.session.commit()

    # G. è¿”å›å‰ç«¯ç»˜å›¾æ•°æ®
    return jsonify({
        "labels": list(stats.keys()),
        "data": list(stats.values()),
        "total_minutes": sum(stats.values())
    })

@app.route('/api/submit_alignment', methods=['POST'])
@login_required
def submit_alignment():
    """æ¥æ”¶å‰ç«¯çš„ RLHF åé¦ˆå¹¶å­˜å…¥æ•°æ®åº“"""
    try:
        data = request.json
        
        # ä¸¥æ ¼å¯¹åº” AlignmentSignal çš„å­—æ®µå
        new_signal = AlignmentSignal(
            user_id=current_user.id,
            input_context=data.get('context', 'Unknown Context'), 
            ai_response=data.get('response', 'User Feedback'), # ä¿®æ­£å­—æ®µå
            reward_score=data.get('score', 0)                  # ä¿®æ­£å­—æ®µå
        )
        
        db.session.add(new_signal)
        db.session.commit()
        
        return jsonify({"status": "success", "message": "Signal Captured"})
        
    except Exception as e:
        print(f"Alignment Error: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500

@app.route('/api/generate_weekly_insight', methods=['POST'])
@login_required
def generate_weekly_insight():
    # 1. è®¾å®šæ—¶é—´èŒƒå›´ (è¿‡å» 7 å¤©)
    end_date = date.today()
    start_date = end_date - timedelta(days=6)
    
    # 2. æŸ¥è¯¢æ—¥å¿—æ•°æ®åº“
    logs = Expenses.query.filter(
        Expenses.user_id == current_user.id,
        Expenses.is_archived == True, 
        Expenses.archive_date >= start_date,
        Expenses.archive_date <= end_date
    ).all()

    # é˜²å¾¡æ€§ç¼–ç¨‹
    if len(logs) < 1:
        return jsonify({
            "status": "error", 
            "message": "Insufficient data fragments. Please log more activity."
        }), 400
    # =======================================================
    # [NEW] 3. è·å–å†å² RLHF åé¦ˆ (The Memory Module)
    # =======================================================
    # æŸ¥è¯¢æœ€è¿‘ 3 æ¡ç”¨æˆ·ç»™è¿‡â€œå·®è¯„â€ (reward_score=1) çš„åé¦ˆ
    negative_feedbacks = AlignmentSignal.query.filter_by(
        user_id=current_user.id,
        reward_score=1  # ä¿®æ­£å­—æ®µå
    ).order_by(AlignmentSignal.timestamp.desc()).limit(3).all()
    
    # æŸ¥è¯¢æœ€è¿‘ 3 æ¡ç”¨æˆ·ç»™è¿‡â€œå¥½è¯„â€ (reward_score=5) çš„åé¦ˆ
    positive_feedbacks = AlignmentSignal.query.filter_by(
        user_id=current_user.id,
        reward_score=5  # ä¿®æ­£å­—æ®µå
    ).order_by(AlignmentSignal.timestamp.desc()).limit(3).all()
    
    # æ„å»ºâ€œä¸Šä¸‹æ–‡è®°å¿†â€å­—ç¬¦ä¸²
    rlhf_context = ""
    
    if negative_feedbacks:
        rlhf_context += "\n[âš ï¸ HISTORY WARNING - USER DISLIKED THESE PREVIOUS ANALYSES]:\n"
        for fb in negative_feedbacks:
            # æˆªå–å‰ 100 ä¸ªå­—ç¬¦ä½œä¸ºä¸Šä¸‹æ–‡å‚è€ƒ
            clean_context = fb.input_context[:150].replace('\n', ' ')
            rlhf_context += f"- User rejected: {clean_context}...\n"
            
    if positive_feedbacks:
        rlhf_context += "\n[âœ… HISTORY SUCCESS - USER LIKED THESE PATTERNS]:\n"
        for fb in positive_feedbacks:
            clean_context = fb.input_context[:150].replace('\n', ' ')
            rlhf_context += f"- User approved: {clean_context}...\n"

    # =======================================================

    # 4. æ•°æ®é¢„å¤„ç† (Log Summary)
    log_summary = "\n".join([
        f"[{l.archive_date} {l.start_time}-{l.end_time}] {l.category}: {l.desc}" 
        for l in logs
    ])
    
    # 5. è·å– Prompt (æ³¨å…¥ RLHF è®°å¿†)
    # æ³¨æ„ï¼šç¡®ä¿ä½ çš„ prompts.py é‡Œçš„å‡½æ•°å·²ç»æ›´æ–°ä¸ºæ¥æ”¶ä¸¤ä¸ªå‚æ•°
    system_prompt = get_weekly_audit_prompt(log_summary, rlhf_context)

    try:
        # --- çœŸå® AI è°ƒç”¨åŒºåŸŸ ---
        # è¯·æ ¹æ®ä½ å®é™…ä½¿ç”¨çš„åº“ (OpenAI / DeepSeek) è§£å¼€ä¸‹é¢çš„æ³¨é‡Š
        
        # response = client.chat.completions.create(
        #     model="deepseek-chat", # æˆ– gpt-4o
        #     messages=[{"role": "system", "content": system_prompt}],
        #     temperature=0.7,
        #     response_format={"type": "json_object"} 
        # )
        # ai_content = response.choices[0].message.content
        # ai_data = json.loads(ai_content)
        
        # --- [FALLBACK] Mock Data (ä¸ºäº†é˜²æ­¢ä½ è¿˜æ²¡é…å¥½ Key å¯¼è‡´æŠ¥é”™) ---
        # --- ä¸€æ—¦ API è°ƒé€šï¼Œå»ºè®®æŠŠä¸‹é¢è¿™æ®µåˆ æ‰æˆ–æ³¨é‡Šæ‰ ---
        import time
        time.sleep(1.5) 
        ai_data = {
            "week_label": "The Recursive Feedback Loop",
            "neural_phase": "HYPER-DRIVE",
            "peak_window": "21:00 - 23:00",
            "deep_work_ratio": 78,
            "primary_mood_color": "#3498db", 
            "achievement": "Integrated Reinforcement Learning Human Feedback (RLHF).",
            "roast": "You are actually coding the logic to audit your own coding logic. This is meta-programming at its finest.",
            "optimization_protocol": "Keep the feedback loop tight."
        }
        # -----------------------------------------------------------

        return jsonify(ai_data)

    except Exception as e:
        print(f"Neural Link Error: {e}")
        return jsonify({"status": "error", "message": f"Neural Link Severed: {str(e)}"}), 500
    
if __name__ == '__main__':
    app.run(debug=True)


#  git checkout -b ai-integration